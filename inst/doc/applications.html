<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Using Pre-Trained Models</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Using Pre-Trained Models</h1>



<div id="applications" class="section level2">
<h2>Applications</h2>
<p>Keras Applications are deep learning models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.</p>
<p>Weights are downloaded automatically when instantiating a model. They are stored at <code>~/.keras/models/</code>.</p>
<p>The following image classification models (with weights trained on ImageNet) are available:</p>
<ul>
<li><a href="../reference/application_xception.html">Xception</a></li>
<li><a href="../reference/application_vgg.html">VGG16</a></li>
<li><a href="../reference/application_vgg.html">VGG19</a></li>
<li><a href="../reference/application_resnet50.html">ResNet50</a></li>
<li><a href="../reference/application_inception_v3.html">InceptionV3</a></li>
<li><a href="../reference/application_mobilenet.html">MobileNet</a></li>
</ul>
</div>
<div id="usage-examples" class="section level2">
<h2>Usage Examples</h2>
<div id="classify-imagenet-classes-with-resnet50" class="section level3">
<h3>Classify ImageNet classes with ResNet50</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># instantiate the model</span>
model &lt;-<span class="st"> </span><span class="kw">application_resnet50</span>(<span class="dt">weights =</span> <span class="st">'imagenet'</span>)

<span class="co"># load the image</span>
img_path &lt;-<span class="st"> &quot;elephant.jpg&quot;</span>
img &lt;-<span class="st"> </span><span class="kw">image_load</span>(img_path, <span class="dt">target_size =</span> <span class="kw">c</span>(<span class="dv">224</span>,<span class="dv">224</span>))
x &lt;-<span class="st"> </span><span class="kw">image_to_array</span>(img)

<span class="co"># ensure we have a 4d tensor with single element in the batch dimension,</span>
<span class="co"># the preprocess the input for prediction using resnet50</span>
<span class="kw">dim</span>(x) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="kw">dim</span>(x))
x &lt;-<span class="st"> </span><span class="kw">imagenet_preprocess_input</span>(x)

<span class="co"># make predictions then decode and print them</span>
preds &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(x)
<span class="kw">imagenet_decode_predictions</span>(preds, <span class="dt">top =</span> <span class="dv">3</span>)[[<span class="dv">1</span>]]</code></pre></div>
<pre><code>  class_name class_description      score
1  n02504013   Indian_elephant 0.90117526
2  n01871265            tusker 0.08774310
3  n02504458  African_elephant 0.01046011</code></pre>
</div>
<div id="extract-features-with-vgg16" class="section level3">
<h3>Extract features with VGG16</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">application_vgg16</span>(<span class="dt">weights =</span> <span class="st">'imagenet'</span>, <span class="dt">include_top =</span> <span class="ot">FALSE</span>)

img_path &lt;-<span class="st"> &quot;elephant.jpg&quot;</span>
img &lt;-<span class="st"> </span><span class="kw">image_load</span>(img_path, <span class="dt">target_size =</span> <span class="kw">c</span>(<span class="dv">224</span>,<span class="dv">224</span>))
x &lt;-<span class="st"> </span><span class="kw">image_to_array</span>(img)
<span class="kw">dim</span>(x) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="kw">dim</span>(x))
x &lt;-<span class="st"> </span><span class="kw">imagenet_preprocess_input</span>(x)

features &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(x)</code></pre></div>
</div>
<div id="extract-features-from-an-arbitrary-intermediate-layer-with-vgg19" class="section level3">
<h3>Extract features from an arbitrary intermediate layer with VGG19</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">base_model &lt;-<span class="st"> </span><span class="kw">application_vgg19</span>(<span class="dt">weights =</span> <span class="st">'imagenet'</span>)
model &lt;-<span class="st"> </span><span class="kw">keras_model</span>(<span class="dt">inputs =</span> base_model<span class="op">$</span>input, 
                     <span class="dt">outputs =</span> <span class="kw">get_layer</span>(base_model, <span class="st">'block4_pool'</span>)<span class="op">$</span>output)

img_path &lt;-<span class="st"> &quot;elephant.jpg&quot;</span>
img &lt;-<span class="st"> </span><span class="kw">image_load</span>(img_path, <span class="dt">target_size =</span> <span class="kw">c</span>(<span class="dv">224</span>,<span class="dv">224</span>))
x &lt;-<span class="st"> </span><span class="kw">image_to_array</span>(img)
<span class="kw">dim</span>(x) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="kw">dim</span>(x)) 
x &lt;-<span class="st"> </span><span class="kw">imagenet_preprocess_input</span>(x)

block4_pool_features &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(x)</code></pre></div>
</div>
<div id="fine-tune-inceptionv3-on-a-new-set-of-classes" class="section level3">
<h3>Fine-tune InceptionV3 on a new set of classes</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create the base pre-trained model</span>
base_model &lt;-<span class="st"> </span><span class="kw">application_inception_v3</span>(<span class="dt">weights =</span> <span class="st">'imagenet'</span>, <span class="dt">include_top =</span> <span class="ot">FALSE</span>)

<span class="co"># add our custom layers</span>
predictions &lt;-<span class="st"> </span>base_model<span class="op">$</span>output <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_global_average_pooling_2d</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1024</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">200</span>, <span class="dt">activation =</span> <span class="st">'softmax'</span>)

<span class="co"># this is the model we will train</span>
model &lt;-<span class="st"> </span><span class="kw">keras_model</span>(<span class="dt">inputs =</span> base_model<span class="op">$</span>input, <span class="dt">outputs =</span> predictions)

<span class="co"># first: train only the top layers (which were randomly initialized)</span>
<span class="co"># i.e. freeze all convolutional InceptionV3 layers</span>
<span class="cf">for</span> (layer <span class="cf">in</span> base_model<span class="op">$</span>layers)
  layer<span class="op">$</span>trainable &lt;-<span class="st"> </span><span class="ot">FALSE</span>

<span class="co"># compile the model (should be done *after* setting layers to non-trainable)</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">optimizer =</span> <span class="st">'rmsprop'</span>, <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>)

<span class="co"># train the model on the new data for a few epochs</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit_generator</span>(...)

<span class="co"># at this point, the top layers are well trained and we can start fine-tuning</span>
<span class="co"># convolutional layers from inception V3. We will freeze the bottom N layers</span>
<span class="co"># and train the remaining top layers.</span>

<span class="co"># let's visualize layer names and layer indices to see how many layers</span>
<span class="co"># we should freeze:</span>
layers &lt;-<span class="st"> </span>base_model<span class="op">$</span>layers
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(layers))
  <span class="kw">cat</span>(i, layers[[i]]<span class="op">$</span>name, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)

<span class="co"># we chose to train the top 2 inception blocks, i.e. we will freeze</span>
<span class="co"># the first 172 layers and unfreeze the rest:</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">172</span>)
  layers[[i]]<span class="op">$</span>trainable &lt;-<span class="st"> </span><span class="ot">FALSE</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">173</span><span class="op">:</span><span class="kw">length</span>(layers))
  layers[[i]]<span class="op">$</span>trainable &lt;-<span class="st"> </span><span class="ot">TRUE</span>

<span class="co"># we need to recompile the model for these modifications to take effect</span>
<span class="co"># we use SGD with a low learning rate</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(
  <span class="dt">optimizer =</span> <span class="kw">optimizer_sgd</span>(<span class="dt">lr =</span> <span class="fl">0.0001</span>, <span class="dt">momentum =</span> <span class="fl">0.9</span>), 
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>
)

<span class="co"># we train our model again (this time fine-tuning the top 2 inception blocks</span>
<span class="co"># alongside the top Dense layers</span>
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit_generator</span>(...)</code></pre></div>
</div>
<div id="build-inceptionv3-over-a-custom-input-tensor" class="section level3">
<h3>Build InceptionV3 over a custom input tensor</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># this could also be the output a different Keras model or layer</span>
input_tensor &lt;-<span class="st"> </span><span class="kw">layer_input</span>(<span class="dt">shape =</span> <span class="kw">c</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))

model &lt;-<span class="st"> </span><span class="kw">application_inception_V3</span>(<span class="dt">input_tensor =</span> input_tensor, 
                                  <span class="dt">weights=</span><span class="st">'imagenet'</span>, 
                                  <span class="dt">include_top =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="additional-examples" class="section level3">
<h3>Additional examples</h3>
<p>The VGG16 model is the basis for the <a href="https://rstudio.github.io/keras/articles/examples/deep_dream.html">Deep dream</a> Keras example script.</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
